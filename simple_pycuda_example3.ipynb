{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2019, 1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nDot product (Inner product)\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pycuda\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "\n",
    "from pycuda.compiler import SourceModule\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(pycuda.VERSION)\n",
    "\n",
    "\"\"\"\n",
    "Dot product (Inner product)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_LENGTH = 64\n",
    "BLOCKSIZE = 16\n",
    "GRIDSIZE = int(np.ceil(VECTOR_LENGTH/BLOCKSIZE))\n",
    "THREAD_PER_BLOCK = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a tensor and copy it to gpu memory\n",
    "# Randomly initialize a vector\n",
    "#a = np.ones(shape=(64*64), dtype=np.float32)\n",
    "a = np.random.randn(VECTOR_LENGTH)\n",
    "a = a.astype(np.float32)\n",
    "b = np.ones(shape=(VECTOR_LENGTH), dtype=np.float32)\n",
    "# Allocate memory at device\n",
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "b_gpu = cuda.mem_alloc(b.nbytes)\n",
    "# Allocate same size of memory for result vector\n",
    "result = np.zeros(4, dtype=np.float32)\n",
    "result_gpu = cuda.mem_alloc(result.nbytes)\n",
    "# Copy the cpu vector to gpu\n",
    "cuda.memcpy_htod(a_gpu, a)\n",
    "cuda.memcpy_htod(b_gpu, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void addTest2D(float *a, float *b, float *res)\n",
    "    {\n",
    "        __shared__ float cache[16];\n",
    "        int blockId = blockIdx.x + blockIdx.y * gridDim.x;\n",
    "        int idx = blockId * (blockDim.x * blockDim.y * blockDim.z)\n",
    "        + (threadIdx.z * (blockDim.x * blockDim.y))\n",
    "        + (threadIdx.y * blockDim.x)\n",
    "        + threadIdx.x;\n",
    "        // Add a and b\n",
    "        cache[threadIdx.x] = a[idx] * b[idx];\n",
    "        \n",
    "        // waiting to finish the jobs\n",
    "        __syncthreads();\n",
    "        \n",
    "        // sum all elements of cache at parallel\n",
    "        int i = blockDim.x/2;\n",
    "        while(i != 0)\n",
    "        {\n",
    "            if(threadIdx.x < i)\n",
    "            {\n",
    "                cache[threadIdx.x] += cache[threadIdx.x + i];\n",
    "            }\n",
    "            // syncthread makes stop every thread until they call syncthread each.\n",
    "            // In this case, if this sync is in the if sentence, this will make the system stopped.\n",
    "            __syncthreads();\n",
    "            i /= 2;\n",
    "        }\n",
    "        \n",
    "        // need to do final cummulatiuon on cpu for efficiency\n",
    "        if(threadIdx.x == 0)\n",
    "        {\n",
    "            res[blockIdx.x] = cache[0];\n",
    "        }\n",
    "    }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for gpu operation :  0.0006589889526367188\n"
     ]
    }
   ],
   "source": [
    "# Let's compare operating time\n",
    "# GPU\n",
    "startTime = time.time()\n",
    "func = mod.get_function(\"addTest2D\")\n",
    "func(a_gpu, b_gpu, result_gpu, block=(THREAD_PER_BLOCK,1,1), grid =(GRIDSIZE,1))\n",
    "consumedTime = time.time() - startTime\n",
    "print(\"Time for gpu operation : \", consumedTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time for cpu operation :  9.703636169433594e-05\n"
     ]
    }
   ],
   "source": [
    "# CPU\n",
    "startTime = time.time()\n",
    "result_cpu = np.dot(a, b)\n",
    "consumedTime = time.time() - startTime\n",
    "print(\"Time for cpu operation : \", consumedTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the result from device to host\n",
    "result = np.zeros(shape=(4), dtype=np.float32)\n",
    "cuda.memcpy_dtoh(result, result_gpu)\n",
    "a_gpu.free()\n",
    "b_gpu.free()\n",
    "result_gpu.free()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is it same? :  False\n"
     ]
    }
   ],
   "source": [
    "# Compare the results\n",
    "print(\"Is it same? : \", (result == result_cpu).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.5065165"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-6.506517"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
